{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-42a41769511e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Aditya - HP\\Desktop\\BE PROJECT\\data.csv\")\n",
    "df=df.set_index('DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\rohit\\Desktop\\BE_PROJECT\\chicago_crime_2016.csv')\n",
    "crime_graph1 = df1[['Primary Type', 'Arrest']].groupby('Primary Type').count()['Arrest']\n",
    "\n",
    "crime_graph1.plot(kind = 'barh', figsize= (10,6), fontsize= 8, title = 'Arrested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crime= 1 #Assault\n",
    "target_names = ['Lat','Long']\n",
    "shift_steps = 1*24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = df[target_names].shift(-shift_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_names].head(shift_steps + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.values[0:-shift_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_data))\n",
    "print(\"Shape:\", x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df_targets.values[:-shift_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(x_data)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data[0:num_train]\n",
    "x_test = x_data[num_train:]\n",
    "len(x_train) + len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_data[0:num_train]\n",
    "y_test = y_data[num_train:]\n",
    "len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x_signals = x_data.shape[1]\n",
    "num_x_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_y_signals = y_data.shape[1]\n",
    "num_y_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", np.min(x_train))\n",
    "print(\"Max:\", np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", np.min(x_train_scaled))\n",
    "print(\"Max:\", np.max(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_scaled.shape)\n",
    "print(y_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    while True:\n",
    "        x_shape = (batch_size, sequence_length, num_x_signals)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "        y_shape = (batch_size, sequence_length, num_y_signals)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
    "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 24*7*8\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 0   # First sequence in the batch.\n",
    "signal = 0  # First signal from the 10 input-signals.\n",
    "seq = x_batch[batch, :, signal]\n",
    "plt.plot(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = y_batch[batch, :, signal]\n",
    "plt.plot(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(x_test_scaled, axis=0),\n",
    "                   np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=512,\n",
    "              return_sequences=True,\n",
    "              input_shape=(None, num_x_signals,)))\n",
    "model.add(Dense(num_y_signals, activation='sigmoid'))\n",
    "if False:\n",
    "    from tensorflow.python.keras.initializers import RandomUniform\n",
    "    init = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "\n",
    "    model.add(Dense(num_y_signals,\n",
    "                    activation='linear',\n",
    "                    kernel_initializer=init))\n",
    "warmup_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n",
    "                                        predictions=y_pred_slice)\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "model.compile(loss=loss_mse_warmup, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = '23_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5, verbose=1)\n",
    "callback_tensorboard = TensorBoard(log_dir='./23_logs/',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(x_test_scaled, axis=0),\n",
    "                        y=np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-91ddf97231a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss (test-set):\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for res, metric in zip(result, model.metrics_names):\n",
    "        print(\"{0}: {1:.3e}\".format(metric, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(start_idx, length=100, train=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x = x_train_scaled\n",
    "        y_true = y_train\n",
    "    else:\n",
    "        # Use test-data.\n",
    "        x = x_test_scaled\n",
    "        y_true = y_test\n",
    "    \n",
    "    # End-index for the sequences.\n",
    "    end_idx = start_idx + length\n",
    "    \n",
    "    # Select the sequences from the given start-index and\n",
    "    # of the given length.\n",
    "    x = x[start_idx:end_idx]\n",
    "    y_true = y_true[start_idx:end_idx]\n",
    "    \n",
    "    # Input-signals for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # The output of the model is between 0 and 1.\n",
    "    # Do an inverse map to get it back to the scale\n",
    "    # of the original data-set.\n",
    "    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n",
    "    \n",
    "    # For each output-signal.\n",
    "    for signal in range(len(target_names)):\n",
    "        # Get the output-signal predicted by the model.\n",
    "        signal_pred = y_pred_rescaled[:, signal]\n",
    "        \n",
    "        # Get the true output-signal from the data-set.\n",
    "        signal_true = y_true[:, signal]\n",
    "\n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        # Plot and compare the two signals.\n",
    "        plt.plot(signal_true, label='true')\n",
    "        plt.plot(signal_pred, label='pred')\n",
    "        \n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        plt.ylabel(target_names[signal])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ea0ed5102c7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-05bc2b2bcacf>\u001b[0m in \u001b[0;36mplot_comparison\u001b[1;34m(start_idx, length, train)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Use test-data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test_scaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "plot_comparison(start_idx=200, length=1000, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
