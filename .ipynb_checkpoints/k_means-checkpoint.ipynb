{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spras\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=24160, step=1)\n"
     ]
    }
   ],
   "source": [
    "SNF1 = pd.read_excel(r\"C:\\Users\\spras\\OneDrive\\Documents\\GitHub\\Predective-Policing-\\assault.xlsx\")\n",
    "SNF = SNF1.iloc[:, 0:8]\n",
    "y = SNF1.iloc[:,8]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(SNF[[\"X\",\"Y\"]])\n",
    "SNF[[\"X\",\"Y\"]] = scaler.transform(SNF[[\"X\",\"Y\"]])\n",
    "SNF=SNF[abs(SNF[\"Y\"])<100]\n",
    "SNF.index=range(len(SNF))\n",
    "print(SNF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spras\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating season features...\n",
      "Creating Lat/Long feature...\n",
      "Creating address features...\n",
      "Creating dummy variables...\n",
      "Joining features...\n",
      "Droping processed columns...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def normalize(data): \n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    return data\n",
    "\n",
    "SNF['X'] = normalize(SNF.X)\n",
    "SNF['Y'] = normalize(SNF.Y)\n",
    "\n",
    "def parse_time(x):\n",
    "    DD=datetime.strptime(str(x),\"%Y-%m-%d %H:%M:%S\")\n",
    "    time=DD.hour\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time, day, month, year\n",
    "\n",
    "#getting season : summer, fall, winter, spring from months column\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    feature_list=df.columns.tolist()\n",
    "    \n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print (\"Parsing dates...\")\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    \n",
    "    print (\"Creating season features...\")\n",
    "    cleanData[\"Summer\"], cleanData[\"Fall\"], cleanData[\"Winter\"], cleanData[\"Spring\"]=zip(*cleanData[\"Month\"].apply(get_season))\n",
    "    print(\"Creating Lat/Long feature...\")\n",
    "    xy_scaler = preprocessing.StandardScaler()\n",
    "    xy_scaler.fit(cleanData[[\"X\",\"Y\"]])\n",
    "    cleanData[[\"X\",\"Y\"]] = xy_scaler.transform(cleanData[[\"X\",\"Y\"]])\n",
    "    #set outliers to 0\n",
    "    cleanData[\"X\"]=cleanData[\"X\"].apply(lambda x: 0 if abs(x)>5 else x)\n",
    "    cleanData[\"Y\"]=cleanData[\"Y\"].apply(lambda y: 0 if abs(y)>5 else y)\n",
    "    print (\"Creating address features...\")\n",
    "    #recoding address as 0: if no interaction , 1: if interaction\n",
    "    cleanData[\"Addr\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    print (\"Creating dummy variables...\")\n",
    "    PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    DAYOfWeek = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='WEEK')\n",
    "    TIME = pd.get_dummies(cleanData['Time'],prefix='HOUR')\n",
    "    Day = pd.get_dummies(cleanData['Day'],prefix='DAY')\n",
    "    Month = pd.get_dummies(cleanData['Month'],prefix='MONTH')\n",
    "    Year = pd.get_dummies(cleanData['Year'],prefix='YEAR')\n",
    "    \n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    \n",
    "    print (\"Joining features...\")\n",
    "    features = pd.concat([cleanData[feature_list],PD,DAYOfWeek,TIME,Day,Month,Year],axis=1)\n",
    "    \n",
    "    print (\"Droping processed columns...\")\n",
    "    cleanFeatures=features.drop([\"PdDistrict\",\"DayOfWeek\",\"Address\",\"Dates\",\"Time\",\"Day\",\"Month\",\"Year\"],\\\n",
    "                                axis=1,inplace=False)\n",
    "    \n",
    "    print('Done!')\n",
    "    \n",
    "    return cleanFeatures\n",
    "\n",
    "features = preprocess_data(SNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(features, test_size = 0.3, random_state = 0)\n",
    "y1_train, y1_test = train_test_split(y,test_size = 0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans = kmeans.fit_predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4603476821192053\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(features)):\n",
    "    if kmeans[i] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
